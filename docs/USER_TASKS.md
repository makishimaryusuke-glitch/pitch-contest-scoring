# ユーザーに依頼が必要な作業

## ✅ 実装済みの改善

以下の改善は実装済みです：

1. ✅ **改善版プロンプトの適用**
   - 具体的なルーブリックを追加
   - スコアリング基準を明確化
   - 評価のポイントをリスト化
   - Few-shot Learning用の評価例を追加

2. ✅ **温度設定の最適化**
   - OpenAI: 0.3 → 0.1に変更
   - Gemini: 0.1に設定

3. ✅ **評価理由の詳細化**
   - 100文字 → 200文字程度に拡張
   - より具体的な説明を要求

## 📋 ユーザーに依頼が必要な作業

### 1. 評価例の収集と追加（高優先度）

現在のプロンプトには一般的な評価例が含まれていますが、実際の作品に基づいた評価例を追加することで、さらに精度が向上します。

#### 必要な作業
- **過去の優秀作品（高得点作品）の例を収集**
  - 各評価項目で8-10点を獲得した作品
  - 評価理由とともに記録

- **中得点作品の例を収集**
  - 各評価項目で5-7点を獲得した作品
  - 評価理由とともに記録

- **低得点作品の例を収集**
  - 各評価項目で0-4点を獲得した作品
  - 評価理由とともに記録

#### 実装方法
収集した評価例を`utils/ai_scoring.py`の各プロンプトの【評価例】セクションに追加してください。

### 2. 基準データセットの作成（中優先度）

AI採点の精度を検証するための基準データセットを作成してください。

#### 必要な作業
1. **過去のコンテストから10-20作品を選択**
   - 各スコア帯から均等に選択
   - 高得点（45-60点）、中得点（30-44点）、低得点（0-29点）

2. **複数の審査員（3-5名）に採点してもらう**
   - 各評価項目ごとに採点
   - 評価理由も記録

3. **審査員間の合意度が高い作品を選定**
   - 審査員間のスコアのばらつきが小さい作品
   - 標準偏差が1点以内の作品を優先

4. **データをCSV形式で保存**
   - 作品ID、各評価項目のスコア、評価理由
   - 審査員ごとの採点結果

#### データ形式の例
```csv
作品ID,審査員,着眼点の独創性,背景のリアリティ,仮説検証の適切性,分析の深さ,現場への還元,波及効果,総合スコア
1,審査員A,9,8,7,8,9,8,49
1,審査員B,9,9,7,8,9,8,50
1,審査員C,8,8,8,8,9,8,49
```

### 3. 検証データセットの作成（中優先度）

基準データセットとは別に、AI採点と人的採点を比較するための検証データセットを作成してください。

#### 必要な作業
1. **基準データセットとは別の5-10作品を選択**
   - 様々なスコア帯から選択

2. **AI採点と人的採点を比較**
   - 同じ作品をAIと審査員で採点
   - 差異を分析

3. **差異が大きい場合はプロンプトを調整**
   - どの評価項目で差異が大きいか
   - プロンプトの改善点を特定

### 4. スコアリングルーブリックの精緻化（低優先度）

現在のルーブリックは一般的なものですが、実際の採点結果を見て、より具体的なルーブリックを作成してください。

#### 必要な作業
1. **過去の採点結果を分析**
   - 各スコア帯の作品の特徴を分析
   - スコアリングの傾向を把握

2. **ルーブリックを精緻化**
   - より具体的な評価基準を追加
   - 各スコア帯の特徴を明確化

3. **プロンプトに反映**
   - 精緻化したルーブリックをプロンプトに追加

## 🎯 推奨される作業順序

1. **まず評価例を収集**（すぐに効果あり）
   - 過去の優秀作品から評価例を収集
   - プロンプトに追加

2. **基準データセットを作成**（検証のため）
   - 10-20作品を複数審査員で採点
   - データを保存

3. **検証データセットでテスト**（精度確認）
   - AI採点と人的採点を比較
   - 差異を分析

4. **ルーブリックを精緻化**（長期的な改善）
   - 採点結果を分析
   - ルーブリックを改善

## 📊 評価指標

以下の指標でAI採点の精度を評価してください：

- **相関係数**: AI採点と人的採点の相関（目標: 0.8以上）
- **平均絶対誤差**: AI採点と人的採点の差の平均（目標: 1点以内）
- **一致率**: 完全一致する割合（目標: 60%以上）
- **再現性**: 同じ資料を複数回採点した場合のばらつき（目標: 標準偏差1点以内）

## 📝 データの保存場所

収集したデータは以下の場所に保存してください：

- **評価例**: `docs/evaluation_examples/`
- **基準データセット**: `data/reference_dataset/`
- **検証データセット**: `data/validation_dataset/`

## 🔍 継続的な改善

定期的に以下を実施してください：

1. **月次レビュー**: 採点結果の分布を確認
2. **四半期レビュー**: 人的採点との比較
3. **年次レビュー**: プロンプトの見直しと改善

## 💡 ヒント

- 評価例は実際の作品から抜粋するのが効果的です
- 審査員間の合意度が高い作品を選ぶと、基準データセットとして信頼性が高まります
- 定期的に検証することで、AI採点の精度を継続的に向上させることができます




